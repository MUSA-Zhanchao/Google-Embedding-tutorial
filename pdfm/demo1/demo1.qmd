---
title: "Zillow Home Value Index Analysis with PDFM Embeddings"
subtitle: "Comparing Linear, Ridge, and Lasso Regression Models"
author: "Zhanchao Yang"
format:
  html:
    theme: cosmo
    toc: true
    code-fold: show
    code-tools: true
execute:
  eval: false
  warning: false
  message: false
---

## Introduction

This document demonstrates the application of **Population Dynamics Foundation Model (PDFM)** embeddings to predict Zillow Home Value Index (ZHVI) data. PDFM embeddings are 330-dimensional vector representations that capture complex spatial and demographic patterns.

### Objectives

1. **Load and visualize** Zillow Home Value Index data with geospatial mapping
2. **Join** PDFM embeddings with home value data
3. **Build regression models** to predict home values:
   - Linear Regression (baseline)
   - Ridge Regression (L2 regularization)
   - Lasso Regression (L1 regularization with feature selection)
4. **Evaluate and visualize** model performance

### Why Ridge and Lasso Regression?

Ridge and Lasso regression are particularly useful when working with high-dimensional embeddings (330 features) because they:

- **Ridge Regression (L2)**:
  - Penalizes large coefficients to prevent overfitting
  - Keeps all features but shrinks their impact
  - Performs well when many features contribute to the outcome

- **Lasso Regression (L1)**:
  - Performs automatic feature selection by shrinking some coefficients to zero
  - Identifies the most important embedding dimensions
  - Produces sparse models that are easier to interpret

- **Both**:
  - Use cross-validation to optimize the regularization parameter (lambda)
  - More computationally efficient than stepwise regression
  - Provide better generalization on unseen data


## Setup and Data Loading

### Load Required Libraries

```{r}
#| label: setup
#| echo: false      # hide code
#| warning: false   # hide warnings
#| message: false   # hide messages
#| include: true

# Data manipulation and analysis
library(tidyverse)
library(readr)

# Geospatial data handling
library(sf)
library(leaflet)

# Machine learning and modeling
library(caret)
library(MASS)  # For stepwise regression
library(glmnet)  # For Ridge and Lasso regression

# Model evaluation
library(Metrics)
library(ggplot2)

# For table formatting
library(knitr)
library(kableExtra)

# Set random seed for reproducibility
set.seed(42)
```

### Download Zillow Home Value Index Data

```{r}
#| label: download-zhvi
#| warning: false   # hide warnings
#| message: false

# Download ZHVI data
zhvi <- read.csv("https://github.com/opengeos/datasets/releases/download/us/zillow_home_value_index_by_county.csv")

```

### Load and Prepare ZHVI Data

```{r}
#| label: load-zhvi

# constuct correct State FIPS code and Municipal FIPS code with leading zeros
zhvi_df <- zhvi %>%
  mutate(
    StateCodeFIP = str_pad(as.character(StateCodeFIPS), width = 2, side = "left", pad = "0"),
    MunicipalCodeFIP = str_pad(as.character(MunicipalCodeFIPS), width = 3, side = "left", pad = "0")
  )
# Create place identifier
zhvi_df <- zhvi_df %>%
  mutate(
    place = paste0("geoId/", StateCodeFIP, MunicipalCodeFIP)
  )
```

**Note:** The `place` column creates a unique identifier for each county by combining state and municipal FIPS codes, which will be used to join with geospatial and embedding data.

## Geospatial Data Integration

### Load County Geometries

```{r}
#| label: load-county-geojson
#| warning: false   # hide warnings
#| message: false


county_gdf <- st_read("https://github.com/zyang91/Google-Embedding-tutorial/releases/download/v2.0.0/county.geojson",quiet=TRUE)

couty_gdf <- county_gdf %>%
  dplyr::select(place)
```

### Join ZHVI with County Geometries

```{r}
#| label: join-zhvi-county

zhvi_county_gdf<- county_gdf %>%
  inner_join(
    zhvi_df,
    by = c("place" = "place")
  )
```

## Visualizing Home Values

### Prepare Data for Visualization

```{r}
#| label: prepare-viz-data

# Select specific date column for visualization
target_date <- "X2024.10.31"
viz_gdf <- zhvi_county_gdf %>%
  dplyr::select(RegionName, State, all_of(target_date), geometry)
```

### Create 2D Choropleth Map

```{r}
#| label: map-2d

# Create interactive map with Leaflet
pal <- colorNumeric(
  palette = "Blues",
  domain = viz_gdf[[target_date]],
  na.color = "transparent"
)

leaflet(viz_gdf) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~pal(get(target_date)),
    fillOpacity = 0.7,
    color = "white",
    weight = 1,
    popup = ~paste0(
      "<strong>", RegionName, ", ", State, "</strong><br>",
      "Home Value: $", format(get(target_date), big.mark = ",")
    )
  ) %>%
  addLegend(
    position = "bottomright",
    pal = pal,
    values = ~get(target_date),
    title = "Zillow Home Median Value",
    opacity = 1
  )
```

**Note:** This creates an interactive map where users can hover over counties to see home values. The blue color gradient represents the magnitude of home values.

## PDFM Embeddings Integration

### Load PDFM Embeddings

```{r}
#| label: load-embeddings
#| warning: false   # hide warnings
#| message: false

# Load pre-computed PDFM embeddings
embeddings <- read_csv("https://github.com/zyang91/Google-Embedding-tutorial/releases/download/v2.0.0/county_embeddings.csv")

```

**About PDFM Embeddings:** These 330-dimensional vectors encode complex spatial patterns including:

- Population mobility patterns
- Search behavior trends
- Local economic activity indicators
- Environmental conditions
- Demographic characteristics

### Visualize Single Embedding Feature

```{r}
#| label: visualize-embedding

# Join embeddings with county geometries
df_embed <- county_gdf %>%
  inner_join(embeddings,
    by = "place"
  )

# Select one embedding feature to visualize
feature_col <- "feature329"
viz_embed <- df_embed %>%
  dplyr::select(state, all_of(feature_col), geometry)
```

```{r}
#| label: map-embedding-feature

# Create map
pal_embed <- colorNumeric(
  palette = "Blues",
  domain = viz_embed[[feature_col]],
  na.color = "transparent"
)

leaflet(viz_embed) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~pal_embed(get(feature_col)),
    fillOpacity = 0.7,
    color = "white",
    weight = 1,
    popup = ~paste0(
      "<strong>", state, "</strong><br>",
      feature_col, ": ", round(get(feature_col), 4)
    )
  ) %>%
  addLegend(
    position = "bottomright",
    pal = pal_embed,
    values = ~get(feature_col),
    title = feature_col,
    opacity = 1
  )
```

**Note:** Each of the 330 embedding features captures different spatial patterns. Feature329 is visualized here as an example.

## Regression Modeling

### Prepare Training Data

```{r}
#| label: prepare-modeling-data

# Join ZHVI with embeddings
data <- zhvi_df %>%
  inner_join(
    embeddings,
    by = "place"
  )

# Define embedding features and target variable
embedding_features <- paste0("feature", 0:329)
target_label <- "X2024.10.31"

# Remove rows with missing target values
data <- data %>%
  filter(!is.na(get(target_label)))

# Select only features and target for modeling
modeling_data <- data %>%
  dplyr::select(all_of(c(embedding_features, target_label)))
modeling_data <- modeling_data %>%
  mutate(index = row_number())
# Split into training and testing sets (80/20 split)
train_indices <- createDataPartition(modeling_data$index, p = 0.8, list = FALSE)
train_data <- modeling_data[train_indices, ]
test_data <- modeling_data[-train_indices, ]

```
Test data:604
Train data:2431

### Model 1: Linear Regression (Baseline)

```{r}
#| label: linear-regression

# refine train data
train_data <- train_data %>%
  dplyr::select(-index)

train_data<- train_data %>%
  rename(target = X2024.10.31)

# Fit linear regression model using all features
lr_model <- lm(target ~ ., data = train_data)

summary(lr_model)
```
On training data, adjusted R-squared: **0.8645**, which indicates the model explains a high proportion of variance in home values.

```{r}
# Make predictions on test set
y_pred_lr <- predict(lr_model, newdata = test_data%>%dplyr::select(-index, -X2024.10.31))

y_test <- test_data$X2024.10.31

# Calculate evaluation metrics
lr_mae <- mae(y_test, y_pred_lr)
lr_rmse <- rmse(y_test, y_pred_lr)
lr_r2 <- cor(y_test, y_pred_lr)^2
```

MAE: 42972.12
RMSE: 59355.71
R²: 0.8564

**Linear Regression Interpretation:**

- Uses all 330 embedding features
- No feature selection - may include irrelevant features
- Serves as baseline for comparison

### Model 2: Stepwise Regression

```{r}
#| label: stepwise-regression

# Perform stepwise regression using AIC criterion
# Direction "both" allows both forward and backward selection
# step_model <- stepAIC(
#   lr_model,
#   direction = "both",
#   trace = TRUE  # Set to TRUE to see step-by-step selection
# )

```

**Stepwise Regression Interpretation:**

- Automatically selects most predictive features using AIC (Akaike Information Criterion)
- Balances model fit with complexity
- Typically results in a more parsimonious model
- Shows which embedding dimensions are most important for prediction
- Not possible (it will compute over 54000 models, roughly takes around 6-7 days to finish)


## Model 3: Ridge Regression
```{r}
#| label: ridge-regression

# Prepare matrix format for glmnet (Ridge regression requires matrix input)
x_train <- as.matrix(train_data %>% dplyr::select(-target))
y_train <- train_data$target
x_test <- as.matrix(test_data %>% dplyr::select(-index, -X2024.10.31))

# Perform cross-validation to find optimal lambda
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 10)

# Fit Ridge regression model with optimal lambda
ridge_model <- glmnet(x_train, y_train, alpha = 0, lambda = cv_ridge$lambda.min)

# Make predictions on test set
y_pred_ridge <- predict(ridge_model, newx = x_test, s = cv_ridge$lambda.min)

# Calculate evaluation metrics
ridge_mae <- mae(y_test, y_pred_ridge)
ridge_rmse <- rmse(y_test, y_pred_ridge)
ridge_r2 <- cor(y_test, y_pred_ridge)^2

# Display results
ridge_results <- data.frame(
  Metric = c("MAE", "RMSE", "R²", "Optimal Lambda"),
  Value = c(
    round(ridge_mae, 2),
    round(ridge_rmse, 2),
    round(ridge_r2, 4),
    round(cv_ridge$lambda.min, 4)
  )
)

kable(ridge_results,
      caption = "Ridge Regression Performance Metrics",
      col.names = c("Metric", "Value")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

**Ridge Regression Interpretation:**

- Uses L2 regularization to penalize large coefficients
- Shrinks coefficients but keeps all 330 features (does not perform feature selection)
- Lambda parameter controls the amount of regularization
- Cross-validation used to find optimal lambda value
- Helps prevent overfitting compared to standard linear regression

## Model 4: Lasso Regression
```{r}
#| label: lasso-regression

# Perform cross-validation to find optimal lambda for Lasso
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 10)

# Fit Lasso regression model with optimal lambda
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = cv_lasso$lambda.min)

# Make predictions on test set
y_pred_lasso <- predict(lasso_model, newx = x_test, s = cv_lasso$lambda.min)

# Calculate evaluation metrics
lasso_mae <- mae(y_test, y_pred_lasso)
lasso_rmse <- rmse(y_test, y_pred_lasso)
lasso_r2 <- cor(y_test, y_pred_lasso)^2

# Count number of non-zero coefficients (features selected)
lasso_coefs <- coef(lasso_model, s = cv_lasso$lambda.min)
n_features_selected <- sum(lasso_coefs != 0) - 1  # Subtract 1 for intercept

# Display results
lasso_results <- data.frame(
  Metric = c("MAE", "RMSE", "R²", "Optimal Lambda", "Features Selected"),
  Value = c(
    round(lasso_mae, 2),
    round(lasso_rmse, 2),
    round(lasso_r2, 4),
    round(cv_lasso$lambda.min, 4),
    n_features_selected
  )
)

kable(lasso_results,
      caption = "Lasso Regression Performance Metrics",
      col.names = c("Metric", "Value")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

**Lasso Regression Interpretation:**

- Uses L1 regularization to penalize large coefficients
- Performs automatic feature selection by shrinking some coefficients to exactly zero
- Lambda parameter controls the amount of regularization
- Cross-validation used to find optimal lambda value
- Results in a sparse model with fewer features than Ridge regression
- Helps identify the most important embedding dimensions for prediction

### Model Comparison

```{r}
#| label: model-comparison

# Create comparison dataframe with all models
model_comparison <- data.frame(
  Model = c("Linear Regression", "Ridge Regression", "Lasso Regression"),
  MAE = c(
    round(lr_mae, 2),
    round(ridge_mae, 2),
    round(lasso_mae, 2)
  ),
  RMSE = c(
    round(lr_rmse, 2),
    round(ridge_rmse, 2),
    round(lasso_rmse, 2)
  ),
  R_squared = c(
    round(lr_r2, 4),
    round(ridge_r2, 4),
    round(lasso_r2, 4)
  ),
  Features_Used = c(
    330,
    330,
    n_features_selected
  )
)

kable(model_comparison,
      caption = "Comparison of Regression Models",
      col.names = c("Model", "MAE", "RMSE", "R²", "Features Used")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  row_spec(which.min(model_comparison$RMSE), bold = TRUE, color = "white", background = "#4CAF50")
```

**Key Insights:**

- Compare which model performs better on unseen data
- Ridge regression uses all features but with regularization to prevent overfitting
- Lasso regression performs feature selection, using fewer features while maintaining accuracy
- Feature reduction can lead to better interpretability and faster predictions
- The best performing model (lowest RMSE) is highlighted in green

## Visualization of Model Performance

### Actual vs. Predicted Plot - Linear Regression

```{r}
#| label: plot-lr

# Create evaluation dataframe for linear regression
eval_df_lr <- data.frame(
  actual = y_test,
  predicted = y_pred_lr
)

# Plot
ggplot(eval_df_lr, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  coord_fixed(xlim = c(0, 1000000), ylim = c(0, 1000000)) +
  labs(
    title = "Linear Regression: Actual vs Predicted",
    subtitle = paste0("R² = ", round(lr_r2, 4)),
    x = "Actual Home Value ($)",
    y = "Predicted Home Value ($)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  ) +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)
```

### Actual vs. Predicted Plot - Ridge Regression

```{r}
#| label: plot-ridge

# Create evaluation dataframe for Ridge regression
eval_df_ridge <- data.frame(
  actual = y_test,
  predicted = as.vector(y_pred_ridge)
)

# Plot
ggplot(eval_df_ridge, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.5, color = "darkgreen") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  coord_fixed(xlim = c(0, 1000000), ylim = c(0, 1000000)) +
  labs(
    title = "Ridge Regression: Actual vs Predicted",
    subtitle = paste0("R² = ", round(ridge_r2, 4)),
    x = "Actual Home Value ($)",
    y = "Predicted Home Value ($)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  ) +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)
```

**Interpretation of Scatter Plots:**

- Points along the red diagonal line indicate perfect predictions
- Points above the line = model overestimates home value
- Points below the line = model underestimates home value
- Tighter clustering around the diagonal = better model performance

### Actual vs. Predicted Plot - Lasso Regression

```{r}
#| label: plot-lasso

# Create evaluation dataframe for Lasso regression
eval_df_lasso <- data.frame(
  actual = y_test,
  predicted = as.vector(y_pred_lasso)
)

# Plot
ggplot(eval_df_lasso, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.5, color = "darkorange") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  coord_fixed(xlim = c(0, 1000000), ylim = c(0, 1000000)) +
  labs(
    title = "Lasso Regression: Actual vs Predicted",
    subtitle = paste0("R² = ", round(lasso_r2, 4), " | Features: ", n_features_selected, "/330"),
    x = "Actual Home Value ($)",
    y = "Predicted Home Value ($)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  ) +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma)
```

## Spatial Visualization of Prediction Errors

### Calculate Prediction Differences

```{r}
#| label: calc-differences

# Add test data indices back to identify counties
test_data_with_place <- modeling_data[-train_indices, ] %>%
  mutate(row_idx = row_number())

# Get the original place identifiers for test data
test_places <- data[test_data$index, "place"]

# Create comparison dataframe
prediction_comparison <- data.frame(
  place = test_places,
  actual = y_test,
  pred_lr = y_pred_lr,
  pred_ridge = as.vector(y_pred_ridge),
  pred_lasso = as.vector(y_pred_lasso)
) %>%
  mutate(
    diff_lr = pred_lr - actual,
    diff_ridge = pred_ridge - actual,
    diff_lasso = pred_lasso - actual
  )
```

### Map Prediction Errors

```{r}
#| label: map-errors

# Join prediction differences with county geometries
error_map_data <- county_gdf %>%
  inner_join(prediction_comparison, by = "place")

# Create color palette for differences (red = underestimate, blue = overestimate)
pal_diff <- colorNumeric(
  palette = c("blue", "white", "red"),
  domain = c(-200000, 200000),
  na.color = "gray"
)

# Create interactive map showing Lasso regression errors
leaflet(error_map_data) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~pal_diff(diff_lasso),
    fillOpacity = 0.7,
    color = "white",
    weight = 1,
    popup = ~paste0(
      "<strong>County</strong><br>",
      "Actual: $", format(round(actual), big.mark = ","), "<br>",
      "Predicted (Lasso): $", format(round(pred_lasso), big.mark = ","), "<br>",
      "Difference: $", format(round(diff_lasso), big.mark = ",")
    )
  ) %>%
  addLegend(
    position = "bottomright",
    pal = pal_diff,
    values = ~diff_lasso,
    title = "Prediction Error<br>(Lasso Model)",
    opacity = 1,
    labFormat = labelFormat(prefix = "$")
  )
```

**Spatial Error Analysis:**

- **Red areas**: Model underestimates home values (actual > predicted)
- **Blue areas**: Model overestimates home values (actual < predicted)
- **White areas**: Predictions close to actual values
- This spatial visualization can reveal geographic patterns in model performance
- Systematic errors in specific regions may indicate missing spatial features or local market conditions not captured by embeddings

## Summary and Conclusions

### Key Findings

1. **PDFM Embeddings as Features**: The 330-dimensional PDFM embeddings successfully capture spatial patterns relevant to home value prediction.

2. **Model Performance**:
   - Linear regression provides a straightforward baseline using all features
   - Ridge regression uses L2 regularization to reduce overfitting while keeping all features
   - Lasso regression performs automatic feature selection through L1 regularization

3. **Regularization Benefits**:
   - Reduced overfitting compared to standard linear regression
   - Ridge: Shrinks coefficients but maintains all 330 features
   - Lasso: Identifies most important embedding dimensions through feature selection
   - Cross-validation ensures optimal regularization strength (lambda)
   - Improved generalization to unseen data

4. **Spatial Patterns**: Error maps reveal geographic variations in prediction accuracy, suggesting opportunities for:
   - Regional model calibration
   - Incorporation of additional local features
   - Investigation of market-specific factors

### Methodological Considerations

**Advantages of Using Embeddings:**

- Captures complex, non-linear relationships
- Incorporates diverse data sources (mobility, search trends, environment)
- Transfer learning from large-scale models
- Rich spatial representation

**Limitations:**

- Black-box nature makes interpretation challenging
- Embeddings may encode biases from training data
- Computational requirements for high-dimensional data
- Model may not capture hyperlocal market dynamics

### Future Directions

1. **Advanced Models**: Try ensemble methods (Random Forest, XGBoost) or neural networks
2. **Feature Engineering**: Combine embeddings with traditional features (square footage, bedrooms, etc.)

## References

- Google Research: Population Dynamics Foundation Model (PDFM)
- Zillow Home Value Index (ZHVI) Database
- [Dr. Qiusheng Wu PDFM Tutorial](https://github.com/opengeos/GeoAI-Tutorials)
- [Google PDFM Embedding](https://github.com/google-research/population-dynamics)

---

